{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c73a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Reimplement the uniform sampling in tianshou. Here is some stuff from the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c585a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from tianshou.data import Batch, ReplayBuffer\n",
    "\n",
    "\n",
    "def _sample_uniform_action(\n",
    "    action_space: gym.Space, rng: np.random.Generator\n",
    ") -> np.ndarray | int:\n",
    "    # Prefer Gym's sampling, but we want controllable RNG for reproducibility.\n",
    "    if isinstance(action_space, gym.spaces.Box):\n",
    "        low = action_space.low\n",
    "        high = action_space.high\n",
    "        a = rng.uniform(low=low, high=high, size=action_space.shape).astype(np.float32)\n",
    "        return np.clip(a, low, high)\n",
    "    elif isinstance(action_space, gym.spaces.Discrete):\n",
    "        return int(rng.integers(0, action_space.n))\n",
    "    elif isinstance(action_space, gym.spaces.MultiDiscrete):\n",
    "        return rng.integers(\n",
    "            low=0, high=action_space.nvec, size=action_space.shape, dtype=np.int64\n",
    "        )\n",
    "    elif isinstance(action_space, gym.spaces.MultiBinary):\n",
    "        return rng.integers(0, 2, size=action_space.n, dtype=np.int8)\n",
    "    else:\n",
    "        # Fallback: uses env's internal RNG\n",
    "        return action_space.sample()\n",
    "\n",
    "\n",
    "def collect_uniform_transitions_tianshou(\n",
    "    env_name: str,\n",
    "    buffer_size: int = 100_000,\n",
    "    seed: int = 0,\n",
    "    print_rejections: bool = True,\n",
    ") -> ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Build a Tianshou ReplayBuffer by:\n",
    "      1) sampling a *uniform* non-terminal state (via env.uniform_reset()),\n",
    "      2) sampling a *uniform* action,\n",
    "      3) stepping once, and\n",
    "      4) storing the transition.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - This assumes your environment wrapper implements `uniform_reset()` that returns a valid non-terminal state.\n",
    "    - If you *don't* have uniform_reset, you cannot generally sample uniformly from the true reachable state space.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "\n",
    "    # If you already have your own UniformExplorationWrapper, keep using it.\n",
    "    # It must implement `uniform_reset()` and (optionally) track `rejections`.\n",
    "    if not hasattr(env, \"uniform_reset\"):\n",
    "        raise AttributeError(\n",
    "            \"env must provide uniform_reset() to sample a uniformly random non-terminal state. \"\n",
    "            \"Wrap it with your UniformExplorationWrapper first.\"\n",
    "        )\n",
    "\n",
    "    buf = ReplayBuffer(size=buffer_size)\n",
    "\n",
    "    # Optional: track how many proposals your wrapper rejected\n",
    "    rejections_before = getattr(env, \"rejections\", 0)\n",
    "\n",
    "    for _ in trange(buffer_size):\n",
    "        obs = env.uniform_reset()  # your wrapper decides what \"uniform\" means\n",
    "        act = _sample_uniform_action(env.action_space, rng)\n",
    "\n",
    "        obs_next, rew, terminated, truncated, info = env.step(act)\n",
    "\n",
    "        # Tianshou expects 1D batch dimension for add(); use shape (1, ...)\n",
    "        b = Batch(\n",
    "            obs=np.asarray(obs),\n",
    "            act=np.asarray(act),\n",
    "            rew=np.asarray(rew, dtype=np.float32),\n",
    "            terminated=np.asarray(terminated, dtype=bool),\n",
    "            truncated=np.asarray(truncated, dtype=bool),\n",
    "            obs_next=np.asarray(obs_next),\n",
    "            info=info,  # optional\n",
    "        )\n",
    "        buf.add(b)\n",
    "\n",
    "    if print_rejections and hasattr(env, \"rejections\"):\n",
    "        rejections_after = getattr(env, \"rejections\", 0)\n",
    "        print(\n",
    "            f\"{rejections_after - rejections_before} of proposed states were rejected\"\n",
    "        )\n",
    "\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "314511b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.99650794, -0.08349816, -0.7885808 ], dtype=float32), {})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"Pendulum-v1\")\n",
    "env.reset(options={\"uniform\": True})\n",
    "# env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829d989a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "env must provide uniform_reset() to sample a uniformly random non-terminal state. Wrap it with your UniformExplorationWrapper first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rb = \u001b[43mcollect_uniform_transitions_tianshou\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPendulum-v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mcollect_uniform_transitions_tianshou\u001b[39m\u001b[34m(env_name, buffer_size, seed, print_rejections)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# If you already have your own UniformExplorationWrapper, keep using it.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# It must implement `uniform_reset()` and (optionally) track `rejections`.\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(env, \u001b[33m\"\u001b[39m\u001b[33muniform_reset\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m     59\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33menv must provide uniform_reset() to sample a uniformly random non-terminal state. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWrap it with your UniformExplorationWrapper first.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     )\n\u001b[32m     63\u001b[39m buf = ReplayBuffer(size=buffer_size)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Optional: track how many proposals your wrapper rejected\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: env must provide uniform_reset() to sample a uniformly random non-terminal state. Wrap it with your UniformExplorationWrapper first."
     ]
    }
   ],
   "source": [
    "rb = collect_uniform_transitions_tianshou(\"Pendulum-v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianshou-td3 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
