{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from functools import partial\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bbrl_utils\n",
    "from bbrl_utils.notebook import setup_tensorboard\n",
    "from bbrl.stats import WelchTTest\n",
    "from bbrl.agents import Agent, Agents, TemporalAgent\n",
    "from bbrl.agents.gymnasium import ParallelGymAgent, make_env\n",
    "from bbrl.workspace import Workspace\n",
    "from bbrl.utils.replay_buffer import ReplayBuffer\n",
    "from pmind_utils import (\n",
    "    DQN,\n",
    "    DDPG,\n",
    "    TD3,\n",
    "    dqn_compute_critic_loss,\n",
    "    ddqn_compute_critic_loss,\n",
    "    run_dqn,\n",
    "    run_ddpg,\n",
    "    run_td3,\n",
    "    run_td3_offline,\n",
    "    get_gym_agent,\n",
    "    get_workspace,\n",
    "    mix_transitions\n",
    ")\n",
    "\n",
    "bbrl_utils.setup()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c33b30",
   "metadata": {},
   "source": [
    "Load all configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24491ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"test_config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bd3d0",
   "metadata": {},
   "source": [
    "# Test used algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_tensorboard(\"./outputs/tblogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d36c3c",
   "metadata": {},
   "source": [
    "### DQN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN(OmegaConf.create(cfg.models.dqn))\n",
    "run_dqn(dqn, dqn_compute_critic_loss)\n",
    "dqn.visualize_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8fac6",
   "metadata": {},
   "source": [
    "### DDQN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59020f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddqn = DQN(OmegaConf.create(cfg.models.ddqn))\n",
    "run_dqn(ddqn, ddqn_compute_critic_loss)\n",
    "ddqn.visualize_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "WelchTTest().plot(\n",
    "    torch.stack(dqn.eval_rewards), torch.stack(ddqn.eval_rewards), save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bab4ef",
   "metadata": {},
   "source": [
    "### DDPG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg = DDPG(OmegaConf.create(cfg.models.ddpg))\n",
    "run_ddpg(ddpg)\n",
    "ddpg.visualize_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cff3c",
   "metadata": {},
   "source": [
    "### TD3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyper-params\n",
    "td3 = TD3(OmegaConf.create(cfg.models.td3))\n",
    "run_td3(td3)\n",
    "td3.visualize_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "WelchTTest().plot(\n",
    "    torch.stack(ddpg.eval_rewards),\n",
    "    torch.stack(td3.eval_rewards),\n",
    "    legends=\"ddpg/td3\",\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c6541",
   "metadata": {},
   "source": [
    "# SANDBOX PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b5604",
   "metadata": {},
   "source": [
    "## Best policy:\n",
    "\n",
    "Get the best policy (to eventually exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6070065",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_td3_best = OmegaConf.create(cfg.models.td3)\n",
    "\n",
    "# accelerate for the sake of test:\n",
    "cfg_td3_best.algorithm.max_epochs = 11000\n",
    "cfg_td3_best.algorithm.learning_starts = 1000\n",
    "\n",
    "td3 = TD3(cfg_td3_best)\n",
    "run_td3(td3)\n",
    "td3.visualize_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefedaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_policy_agent = td3.best_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_agent = get_gym_agent('CartPoleContinuous-v1', num_envs=10, seed=42)\n",
    "workspace_best = get_workspace(best_policy_agent ,gym_agent, epoch_size=10_000)\n",
    "print(workspace_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7de05",
   "metadata": {},
   "source": [
    "## Uniform policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformAgent(Agent):\n",
    "    '''Agent that explores uniformly a given environment'''\n",
    "\n",
    "    # TODO: for now it just does a random walk,\n",
    "    #   need to do jumps instead - random actions in random states\n",
    "    # I think need to modify ParallelGymAgent._reset() method\n",
    "    def __init__(self, env_name):\n",
    "        super().__init__()\n",
    "        self.env = gym.make(env_name) \n",
    "\n",
    "    def forward(self, t: int):\n",
    "        \"\"\"An Agent can use self.workspace\"\"\"\n",
    "        # obs = self.get((\"env/env_obs\", t))\n",
    "        n_env = self.workspace.batch_size()\n",
    "        action = torch.tensor([self.env.action_space.sample() for _ in range(n_env) ], dtype=torch.float32)\n",
    "        self.set((\"action\", t), action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d19360",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_unif = get_workspace(UniformAgent('CartPoleContinuous-v1'), gym_agent, epoch_size=10_000)\n",
    "print(workspace_unif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40992172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poking around with the idea: may be it's easier to implement those \n",
    "# random jumps as episodes of length 2?\n",
    "# for k in range(gym_agent.num_envs):\n",
    "#     env = gym_agent.envs[k]\n",
    "#     env.reset()\n",
    "#     env.state = env.unwrapped.state = env.observation_space.sample()\n",
    "# gym_agent = get_gym_agent('CartPoleContinuous-v1', num_envs=3, seed=42)\n",
    "# t_agents = TemporalAgent(Agents(gym_agent,UniformAgent('CartPoleContinuous-v1')))\n",
    "# workspace = Workspace()\n",
    "# t_agents(workspace, t=1,n_steps=2)\n",
    "# workspace_unif.get_transitions()[\"env/reward\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66127fc8",
   "metadata": {},
   "source": [
    "## Mix transitions in a buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_mixed = mix_transitions(workspace_best, \n",
    "                           workspace_unif,\n",
    "                           batch_size=10_000, \n",
    "                           proportion=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db85183",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_td3_offline = OmegaConf.create(cfg.models.td3)\n",
    "\n",
    "# accelerate for the sake of test:\n",
    "cfg_td3_offline.algorithm.max_epochs = 1000\n",
    "\n",
    "# we don't care about when learning starts for offline:\n",
    "cfg_td3_offline.algorithm.learning_starts = None\n",
    "\n",
    "td3_offline = TD3(cfg_td3_offline)\n",
    "run_td3_offline(td3_offline, rb_mixed)\n",
    "td3_offline.visualize_best()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
